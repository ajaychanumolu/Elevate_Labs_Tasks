{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler from sklearn.impute\n",
    "import SimpleImputer\n",
    "\n",
    "# Load Titanic dataset\n",
    "\n",
    "df = pd.read_csv(“Titanic-Dataset.csv”)\n",
    "\n",
    "# Step 1: Basic Cleaning\n",
    "\n",
    "# Drop irrelevant columns\n",
    "\n",
    "df.drop(columns=\\[‘PassengerId’, ‘Name’, ‘Ticket’, ‘Cabin’\\],\n",
    "inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "\n",
    "# Fill Age with median\n",
    "\n",
    "df\\[‘Age’\\].fillna(df\\[‘Age’\\].median(), inplace=True) \\# Fill Embarked\n",
    "with most frequent value\n",
    "df\\[‘Embarked’\\].fillna(df\\[‘Embarked’\\].mode()\\[0\\], inplace=True)\n",
    "\n",
    "# Step 2: Encode categorical columns\n",
    "\n",
    "# Convert ‘Sex’ and ‘Embarked’ to dummy variables\n",
    "\n",
    "df = pd.get_dummies(df, columns=\\[‘Sex’, ‘Embarked’\\], drop_first=True)\n",
    "\n",
    "# Step 3: Split features and target\n",
    "\n",
    "X = df.drop(columns=\\[‘Survived’\\]) y = df\\[‘Survived’\\]\n",
    "\n",
    "# Step 4: Feature Scaling\n",
    "\n",
    "scaler = StandardScaler() X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n",
    "test_size=0.2, random_state=42)\n",
    "\n",
    "print(“Titanic data cleaned, encoded, scaled, and split successfully!”)"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
